{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrEhWG7hQFz2"
   },
   "source": [
    "# Speech Recognition with AI\n",
    "Brought to you by Daniel Sikar - daniel.sikar@city.ac.uk\n",
    "and\n",
    "City Data Science Society - https://www.datasciencesociety.city/\n",
    "\n",
    "## Natural Language Processing with Convolutional Neural Networks\n",
    "\n",
    "Notebook: https://github.com/dsikar/natural-language-processing/blob/master/NaturalLanguageProcessing.ipynb\n",
    "\n",
    "Tensorflow's Speech Commands Datasets: http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
    "\n",
    "Consisting of:\n",
    "* 65,000 one-second long utterances\n",
    "* 30 short words plus a background noise set\n",
    "* Thousands of different people\n",
    "\n",
    "Using a subset (\"yes\" and \"no\") of Tensorflow's Speech Commands Datasets. The full set consists of 30 words plus a background noise set: _background_noise_, bed, bird, cat, dog, down, eight, five, four, go, happy, house, left, marvin, no, nine, off, on, one, right, seven, sheila, six, stop, three, tree, two, up, wow, yes, zero.\n",
    "\n",
    "Note: In this workshop, we will **not** use the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9XQxOCeThKF"
   },
   "source": [
    "# 1. Getting to know the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZoVotgTgTgbO",
    "outputId": "35aa2a9e-541c-40fe-f28a-88e676a9de6f"
   },
   "outputs": [],
   "source": [
    "# How much space have we got?\n",
    "# !df -h\n",
    "# Command help\n",
    "# !man df\n",
    "# What is on the filesystem?\n",
    "#!ls\n",
    "# Where are we?\n",
    "# !pwd\n",
    "# What files are on the top level / ?\n",
    "# !ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJAZEvYVVFP0"
   },
   "source": [
    "# 2. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zP-6EIsQtif",
    "outputId": "7dd639d6-00a2-422b-9b9e-a7449266312d"
   },
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
    "# !ls\n",
    "!mkdir full_dataset\n",
    "# !ls\n",
    "!tar xvf speech_commands_v0.01.tar.gz -C full_dataset/ \n",
    "# !ls full_dataset\n",
    "!mkdir dataset\n",
    "!mv full_dataset/yes dataset/\n",
    "!mv full_dataset/no dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EXhdbR2ayNB"
   },
   "outputs": [],
   "source": [
    "!ls dataset/yes | wc -l\n",
    "!ls dataset/no | wc -l\n",
    "!ls dataset\n",
    "# !ls dataset/yes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsmYvKeWbPLe"
   },
   "source": [
    "# 3. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-8k0KFHVDU_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koNkhOEeVDVD"
   },
   "source": [
    "# 4. Visualise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "PYAne6bsVDVE",
    "outputId": "f4ba784b-e5b1-47b7-d1fc-7df9fdf01f4b"
   },
   "outputs": [],
   "source": [
    "# Dataset original sample rate 16 kHz\n",
    "# Humans can detect sounds in a frequency range from about 20 Hz to 20 kHz.\n",
    "# We will convert data to 8 kHz given our network architecture (more later)\n",
    "samples_yes, sample_rate = librosa.load('dataset/yes/8d8d9855_nohash_0.wav', sr = 8000)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('\"Yes\" - waveform for file ' + 'dataset/yes/8d8d9855_nohash_0.wav')\n",
    "ax1.set_xlabel('Sample')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, sample_rate/len(samples_yes), sample_rate), samples_yes)\n",
    "ipd.Audio(samples_yes, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "yksflJfHM20A",
    "outputId": "fc2b32da-7fd4-47cf-8c00-8c65746df653"
   },
   "outputs": [],
   "source": [
    "samples_no, sample_rate = librosa.load('dataset/no/8a194ee6_nohash_0.wav', sr = 8000)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('\"NO\" - Waveform for file ' + 'dataset/no/8a194ee6_nohash_0.wav')\n",
    "ax1.set_xlabel('Sample')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, sample_rate/len(samples_no), sample_rate), samples_no)\n",
    "ipd.Audio(samples_no, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TekJpdHVDVH",
    "outputId": "5549ae11-bb12-4c4d-84c7-9da4877a91da"
   },
   "outputs": [],
   "source": [
    "# Data type\n",
    "print(type(samples))\n",
    "# Size\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDsXwftqYHb6",
    "outputId": "62b3bb26-e458-41f2-fc90-fbd6b6082945"
   },
   "outputs": [],
   "source": [
    "# Statistical analysis - can the word be inferred?\n",
    "print(\"No, sample mean:\", np.mean(samples_no))\n",
    "print(\"No, sample std:\", np.std(samples_no))\n",
    "print(\"Yes, sample mean:\", np.mean(samples_yes))\n",
    "print(\"Yes, sample std:\", np.std(samples_yes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4FepQniVDVK",
    "outputId": "df0e7dc2-1886-4a49-d249-349aa6a62537"
   },
   "outputs": [],
   "source": [
    "# Labels\n",
    "labels=os.listdir(train_audio_path)\n",
    "print(\"Audio labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "c-v8oU4_VDVL",
    "outputId": "aa6ccd93-ccf9-4b58-cfd5-a37d116fedf9"
   },
   "outputs": [],
   "source": [
    "# Find count of each label and plot bar graph\n",
    "no_of_recordings=[]\n",
    "for label in labels:\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    no_of_recordings.append(len(waves))\n",
    "    \n",
    "#plot\n",
    "plt.figure()\n",
    "index = np.arange(len(labels))\n",
    "plt.bar(index, no_of_recordings)\n",
    "plt.xlabel('Commands', fontsize=12)\n",
    "plt.ylabel('No of recordings', fontsize=12)\n",
    "plt.xticks(index, labels, fontsize=15, rotation=60)\n",
    "plt.title('No. of recordings for each command')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "uOs6bFxoVDVM",
    "outputId": "218117b9-46d2-4ded-84dc-dde3f5a3fa1a"
   },
   "outputs": [],
   "source": [
    "# Duration\n",
    "duration_of_recordings=[]\n",
    "for label in labels:\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        sample_rate, samples = wavfile.read(train_audio_path + '/' + label + '/' + wav)\n",
    "        duration_of_recordings.append(float(len(samples)/sample_rate))\n",
    "    \n",
    "plt.hist(np.array(duration_of_recordings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCteLkKjVDVN"
   },
   "source": [
    "# 5. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwZQZb2OVDVN",
    "outputId": "ea784177-4984-457c-a8e9-5a77ff11c7c2"
   },
   "outputs": [],
   "source": [
    "train_audio_path = 'dataset'\n",
    "\n",
    "all_wave = []\n",
    "all_label = []\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        # resample\n",
    "        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 8000)\n",
    "        if(len(samples)== 8000) : \n",
    "            # only use 1 second long recordings\n",
    "            all_wave.append(samples)\n",
    "            all_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41wZl_M6ei8B",
    "outputId": "00efc725-3066-4796-a96d-db842d12dfc9"
   },
   "outputs": [],
   "source": [
    "# print size of training dataset\n",
    "print(len(all_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Il8BsTOxVDVO",
    "outputId": "ec32bf08-b56c-4d70-99a9-523eb6c58d98"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "arr_labels=le.fit_transform(all_label)\n",
    "classes= list(le.classes_)\n",
    "# print datatype\n",
    "print(type(classes))\n",
    "# print classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKz8IkKoVDVP"
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "arr_labels=np_utils.to_categorical(arr_labels, num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nf6ZmzFfAva",
    "outputId": "1ad2b120-a5bc-4a5b-c7e1-c2a3c3f580f0"
   },
   "outputs": [],
   "source": [
    "# type\n",
    "print(type(arr_labels))\n",
    "# shape\n",
    "print(arr_labels.shape)\n",
    "# first first index value\n",
    "print(arr_labels[0]) # yes\n",
    "# first last index value\n",
    "print(arr_labels[arr_labels.shape[0]-1]) # yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "vmDUsGcwmWF8",
    "outputId": "f9bd50a2-9529-4252-fbe2-8ba523ebbed0"
   },
   "outputs": [],
   "source": [
    "# Let's look at data again, this time loading from array\n",
    "samples_no = all_wave[0].ravel()\n",
    "sample_rate = 8000\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('\"Yes\" all_wave[0].ravel()')\n",
    "ax1.set_xlabel('Sample')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, sample_rate/len(samples_no), sample_rate), samples_no)\n",
    "print(\"labels: \", arr_labels[0])\n",
    "ipd.Audio(samples_no, rate=sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "uTUgo8DkoNzb",
    "outputId": "7815a5b1-9cae-4785-c5e3-c7c602570cd6"
   },
   "outputs": [],
   "source": [
    "print()\n",
    "samples_no = all_wave[arr_labels.shape[0]-1].ravel()\n",
    "sample_rate = 8000\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('\"No\" arr_labels.shape[0]-1]')\n",
    "ax1.set_xlabel('Sample')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, sample_rate/len(samples_no), sample_rate), samples_no)\n",
    "print(\"labels: \", arr_labels[arr_labels.shape[0]-1])\n",
    "ipd.Audio(samples_no, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4J9_wofFVDVQ"
   },
   "outputs": [],
   "source": [
    "# Reshape the 2D array to 3D since the input to the conv1d must be a 3D array\n",
    "all_wave = np.array(all_wave).reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tjmbea5GhUhT"
   },
   "source": [
    "# 6. Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMOgC_cYVDVR"
   },
   "outputs": [],
   "source": [
    "# Split into training and validation sets 70/30\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave),np.array(y),stratify=arr_labels,test_size = 0.3,random_state=777,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bqEi398VDVR"
   },
   "source": [
    "# 7. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rByRV5zmVDVR",
    "outputId": "abed9758-d121-4aec-8378-9cc3d827027a"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "inputs = Input(shape=(8000,1))\n",
    "\n",
    "#First Conv1D layer\n",
    "conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Second Conv1D layer\n",
    "conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Third Conv1D layer\n",
    "conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Fourth Conv1D layer\n",
    "conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Flatten layer\n",
    "conv = Flatten()(conv)\n",
    "\n",
    "#Dense Layer 1\n",
    "conv = Dense(256, activation='relu')(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Dense Layer 2\n",
    "conv = Dense(128, activation='relu')(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "outputs = Dense(len(labels), activation='softmax')(conv)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JO7e5ktVDVS"
   },
   "outputs": [],
   "source": [
    "# Compile, defining a loss function, optimiser and metrics\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKy96wwLVDVT"
   },
   "outputs": [],
   "source": [
    "# Set early stopping and check pointing\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, min_delta=0.0001) \n",
    "mc = ModelCheckpoint('nlp-model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbZ4uyhYkuEu"
   },
   "source": [
    "# 8. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTxvY0SRVDVT",
    "outputId": "3c768181-a1b5-4b15-b29f-8c036c7d7d1a"
   },
   "outputs": [],
   "source": [
    "# Fit the model (find best parameters)\n",
    "history=model.fit(x_tr, y_tr ,epochs=10, callbacks=[es,mc], batch_size=32, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Egee5nwXQrUW"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('nlp-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTZz324fQrUW",
    "outputId": "865d1319-6740-4244-e31e-2fb70497a642"
   },
   "outputs": [],
   "source": [
    "# verify \n",
    "!ls -lh nlp-model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "m59CuQffVDVU",
    "outputId": "012893ff-c20d-4271-fab1-5114bff16ee3"
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train_loss')\n",
    "pyplot.plot(history.history['val_loss'], label='test_loss')\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTFy_piaVDVV"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "from keras.models import load_model\n",
    "model=load_model('nlp-model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBc6L2bsVDVV"
   },
   "source": [
    "# 9. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJsFQBK3VDVV"
   },
   "outputs": [],
   "source": [
    "def predict(audio):\n",
    "    \"\"\"\n",
    "    Input\n",
    "      audio: array representing audio file\n",
    "    Ouput\n",
    "      prob: \n",
    "      classes:\n",
    "    \"\"\"\n",
    "    prob=model.predict(audio.reshape(1,8000,1))\n",
    "    index=np.argmax(prob[0])\n",
    "    return prob, classes[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "i1AxW5OWVDVX",
    "outputId": "0a487a77-cee2-4ef2-bfb3-44b699a76680"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# print(\"Number of testing examples - len(x_val):\", len(x_val))\n",
    "index=random.randint(0,len(x_val)-1)\n",
    "print(\"Random index selected:\", index)\n",
    "samples=x_val[index].ravel() # x_val[index] shape: (8000, 1), \"samples\" shape: (8000,)\n",
    "print(\"Randomly selected audio:\",classes[np.argmax(y_val[index])])\n",
    "pred, predClass = predict(samples)\n",
    "print(\"Prediction output: \", pred)\n",
    "print(\"Predicted class:\", predClass)\n",
    "sample_rate = 8000\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title(predClass)\n",
    "ax1.set_xlabel('Sample')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)\n",
    "ipd.Audio(samples, rate=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzTvo_Czu0OW"
   },
   "source": [
    "# 10. Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45yPJyMlQrUa",
    "outputId": "e2908793-e1b8-454b-942b-d9411bc24cbd"
   },
   "outputs": [],
   "source": [
    "# TODO Audio capture\n",
    "# TODO Audio preprocessing\n",
    "if(predClass == \"yes\"):\n",
    "  # TODO hardware \n",
    "  print(\"Doors opening\")\n",
    "else:\n",
    "  # TODO hardware \n",
    "  print(\"Doors closing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BalJ890ucHF"
   },
   "source": [
    "# 11. Downloading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "KaAKU2StvTtV",
    "outputId": "f5e5c365-463d-4466-8cdb-0dae66e15e4a"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('nlp-model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPx5JleguchR"
   },
   "source": [
    "# 12. Practical considerations - software versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZQoLMCGQrUa",
    "outputId": "565da28b-d32e-4b2f-f775-51bc4541d18d"
   },
   "outputs": [],
   "source": [
    "# When running the model on other machines, software versions should at least match,\n",
    "# not be lower than on machine where model was trained\n",
    "\n",
    "import keras\n",
    "!python --version\n",
    "print(\"TensorFlow version:\", tensorflow.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NaturalLanguageProcessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
